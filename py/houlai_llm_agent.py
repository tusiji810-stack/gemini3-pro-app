"""
ComfyUI_Ecommerce_LLM_Agent - æ ¸å¿ƒèŠ‚ç‚¹å®ç°

æœ¬æ–‡ä»¶åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒèŠ‚ç‚¹:
1. Universal_LLM_Config: é€šç”¨LLMé…ç½®èŠ‚ç‚¹
2. Ecommerce_Skill_Router: ç”µå•†æŠ€èƒ½è·¯ç”±èŠ‚ç‚¹

åŠŸèƒ½è¯´æ˜:
- æ”¯æŒå¤šæ¨¡æ€LLM (è±†åŒ…/GPT-4o/DeepSeekç­‰)
- æ”¯æŒå›¾ç‰‡+æ–‡æœ¬è¾“å…¥
- YAMLæŠ€èƒ½åº“åŠ¨æ€åŠ è½½
- ç”Ÿæˆé€‚é…Flux/Qwençš„æç¤ºè¯
"""

# ============================================
# ä¾èµ–æ£€æŸ¥ä¸å¯¼å…¥
# ============================================
import sys
import importlib.util

# æ£€æŸ¥å¿…è¦çš„ä¾èµ–åº“æ˜¯å¦å·²å®‰è£…
def check_dependencies():
    """æ£€æŸ¥å¹¶æŠ¥å‘Šä¾èµ–åº“çš„å®‰è£…çŠ¶æ€"""
    required_packages = {
        "openai": "openai>=1.0.0",
        "yaml": "PyYAML>=6.0",
        "PIL": "Pillow>=9.0.0",
        "requests": "requests>=2.28.0",
    }
    
    missing = []
    for module, package in required_packages.items():
        if importlib.util.find_spec(module) is None:
            missing.append(package)
    
    if missing:
        print("=" * 60)
        print("[ComfyUI_Ecommerce_LLM_Agent] é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“!")
        print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print(f"  pip install {' '.join(missing)}")
        print("æˆ–:")
        print("  pip install -r requirements.txt")
        print("=" * 60)
        return False
    return True

# æ‰§è¡Œä¾èµ–æ£€æŸ¥
DEPS_OK = check_dependencies()

# æ ‡å‡†åº“å¯¼å…¥
import os
import io
import base64
import traceback
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥ (åœ¨ä¾èµ–æ£€æŸ¥é€šè¿‡å)
if DEPS_OK:
    import yaml
    from PIL import Image as PILImage
    from openai import OpenAI
    import torch
    import numpy as np

# ============================================
# å…¨å±€å¸¸é‡å®šä¹‰
# ============================================
# æ’ä»¶æ ¹ç›®å½•è·¯å¾„ï¼ˆpyç›®å½•çš„çˆ¶ç›®å½•ï¼Œå³é¡¹ç›®æ ¹ç›®å½•ï¼‰
PLUGIN_ROOT = Path(__file__).parent.parent.absolute()

# æŠ€èƒ½æ–‡ä»¶å¤¹è·¯å¾„
SKILLS_DIR = PLUGIN_ROOT / "skills"

# å›¾ç‰‡å¤„ç†å¸¸é‡
MAX_IMAGES = 4  # æœ€å¤šå¤„ç†4å¼ å›¾ç‰‡
MAX_IMAGE_SIZE = 2048  # å›¾ç‰‡æœ€å¤§å°ºå¯¸

# é»˜è®¤LLMé…ç½®
DEFAULT_BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
DEFAULT_MODEL = "ep-xxx...-xxx"
DEFAULT_SYSTEM_PROMPT = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå•†è§†è§‰å†…å®¹ç”ŸæˆåŠ©æ‰‹ã€‚"

# ============================================
# å·¥å…·å‡½æ•°
# ============================================

# å…¨å±€ç¼“å­˜æŠ€èƒ½åˆ—è¡¨
_SKILLS_CACHE = None
_CUSTOM_SKILLS_DIR = None

def scan_skills_directory(force_refresh: bool = False, custom_path: str = "") -> List[str]:
    """
    æ‰«ææŠ€èƒ½ç›®å½•ä¸‹çš„æ‰€æœ‰YAMLæ–‡ä»¶ï¼Œè¿”å›æŠ€èƒ½é€‰é¡¹åˆ—è¡¨
    
    Args:
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
        custom_path: è‡ªå®šä¹‰æŠ€èƒ½æ–‡ä»¶å¤¹è·¯å¾„
    
    Returns:
        List[str]: æ ¼å¼ä¸º "æ–‡ä»¶å - Keyå" çš„æŠ€èƒ½é€‰é¡¹åˆ—è¡¨
    """
    global _SKILLS_CACHE, _CUSTOM_SKILLS_DIR
    
    # ç¡®å®šä½¿ç”¨çš„æŠ€èƒ½ç›®å½•
    if custom_path and custom_path.strip():
        skills_dir = Path(custom_path.strip())
        _CUSTOM_SKILLS_DIR = skills_dir
    elif _CUSTOM_SKILLS_DIR:
        skills_dir = _CUSTOM_SKILLS_DIR
    else:
        skills_dir = SKILLS_DIR
    
    # ä½¿ç”¨ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
    if not force_refresh and _SKILLS_CACHE is not None:
        return _SKILLS_CACHE
    
    skills = []
    
    # ç¡®ä¿æŠ€èƒ½ç›®å½•å­˜åœ¨
    if not skills_dir.exists():
        print(f"[Ecommerce_Skill_Router] è­¦å‘Š: æŠ€èƒ½ç›®å½•ä¸å­˜åœ¨: {skills_dir}")
        return ["æœªæ‰¾åˆ°æŠ€èƒ½æ–‡ä»¶"]
    
    # éå†æ‰€æœ‰yamlæ–‡ä»¶
    for yaml_file in sorted(skills_dir.glob("*.yaml")):
        try:
            with open(yaml_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
                
            if data and isinstance(data, dict):
                for key in data.keys():
                    # æ ¼å¼: "æ–‡ä»¶å(ä¸å«æ‰©å±•å) - Keyå"
                    display_name = f"{yaml_file.stem} - {key}"
                    skills.append(display_name)
        except Exception as e:
            print(f"[Ecommerce_Skill_Router] è§£ææ–‡ä»¶å¤±è´¥ {yaml_file}: {e}")
            continue
    
    if not skills:
        _SKILLS_CACHE = ["æœªæ‰¾åˆ°æœ‰æ•ˆæŠ€èƒ½"]
    else:
        _SKILLS_CACHE = skills
    
    return _SKILLS_CACHE


def search_skill_by_keyword(keyword: str) -> Optional[str]:
    """
    æ ¹æ®å…³é”®è¯æœç´¢åŒ¹é…çš„æŠ€èƒ½
    
    Args:
        keyword: æœç´¢å…³é”®è¯
    
    Returns:
        Optional[str]: åŒ¹é…çš„æŠ€èƒ½åç§°ï¼Œæœªæ‰¾åˆ°è¿”å›None
    """
    if not keyword or not keyword.strip():
        return None
    
    keyword = keyword.strip().lower()
    skills = scan_skills_directory()
    
    # ç²¾ç¡®åŒ¹é…
    for skill in skills:
        if keyword in skill.lower():
            print(f"[Skill Search] æ‰¾åˆ°åŒ¹é…: {skill}")
            return skill
    
    return None


def load_skill_template(skill_selection: str, custom_path: str = "") -> Optional[str]:
    """
    æ ¹æ®é€‰æ‹©åŠ è½½å¯¹åº”çš„æŠ€èƒ½æ¨¡æ¿
    
    Args:
        skill_selection: æ ¼å¼ä¸º "æ–‡ä»¶å - Keyå"
        custom_path: è‡ªå®šä¹‰æŠ€èƒ½æ–‡ä»¶å¤¹è·¯å¾„
    
    Returns:
        Optional[str]: æ¨¡æ¿å­—ç¬¦ä¸²ï¼Œå¤±è´¥è¿”å›None
    """
    global _CUSTOM_SKILLS_DIR
    
    try:
        # ç¡®å®šä½¿ç”¨çš„æŠ€èƒ½ç›®å½•
        if custom_path and custom_path.strip():
            skills_dir = Path(custom_path.strip())
        elif _CUSTOM_SKILLS_DIR:
            skills_dir = _CUSTOM_SKILLS_DIR
        else:
            skills_dir = SKILLS_DIR
        
        # è§£æé€‰æ‹©å­—ç¬¦ä¸²
        parts = skill_selection.split(" - ", 1)
        if len(parts) != 2:
            return None
        
        filename, key = parts
        yaml_path = skills_dir / f"{filename}.yaml"
        
        if not yaml_path.exists():
            return None
        
        with open(yaml_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        
        if key in data and "template" in data[key]:
            return data[key]["template"]
        
        return None
    except Exception as e:
        print(f"[Ecommerce_Skill_Router] åŠ è½½æ¨¡æ¿å¤±è´¥: {e}")
        return None


def tensor_to_pil(image_tensor: torch.Tensor) -> PILImage.Image:
    """
    å°†ComfyUIçš„Tensorå›¾åƒè½¬æ¢ä¸ºPIL Image
    
    Args:
        image_tensor: ComfyUIå›¾åƒå¼ é‡ [B, H, W, C] æˆ– [H, W, C]
    
    Returns:
        PILImage.Image: PILå›¾åƒå¯¹è±¡
    """
    # å¤„ç†batchç»´åº¦
    if len(image_tensor.shape) == 4:
        # [B, H, W, C] -> å–ç¬¬ä¸€å¼ 
        image_tensor = image_tensor[0]
    
    # [H, W, C] -> è½¬æ¢ä¸ºnumpy
    if isinstance(image_tensor, torch.Tensor):
        image_np = image_tensor.cpu().numpy()
    else:
        image_np = np.array(image_tensor)
    
    # ç¡®ä¿å€¼èŒƒå›´åœ¨0-255
    if image_np.max() <= 1.0:
        image_np = (image_np * 255).astype(np.uint8)
    else:
        image_np = image_np.astype(np.uint8)
    
    # åˆ›å»ºPILå›¾åƒ
    pil_image = PILImage.fromarray(image_np)
    
    # é™åˆ¶æœ€å¤§å°ºå¯¸
    if max(pil_image.size) > MAX_IMAGE_SIZE:
        pil_image.thumbnail((MAX_IMAGE_SIZE, MAX_IMAGE_SIZE), PILImage.Resampling.LANCZOS)
    
    return pil_image


def pil_to_base64(pil_image: PILImage.Image, format: str = "PNG") -> str:
    """
    å°†PIL Imageè½¬æ¢ä¸ºBase64ç¼–ç çš„å­—ç¬¦ä¸²
    
    Args:
        pil_image: PILå›¾åƒå¯¹è±¡
        format: å›¾åƒæ ¼å¼ (PNG/JPEG)
    
    Returns:
        str: Base64ç¼–ç çš„å›¾åƒæ•°æ®
    """
    buffered = io.BytesIO()
    
    # å¦‚æœæ˜¯RGBAæ ¼å¼ä¸”ç›®æ ‡æ ¼å¼æ˜¯JPEGï¼Œéœ€è¦è½¬æ¢
    if format == "JPEG" and pil_image.mode in ("RGBA", "P"):
        pil_image = pil_image.convert("RGB")
    
    pil_image.save(buffered, format=format)
    img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
    return img_str


def create_vision_message(pil_images: List[PILImage.Image], text_prompt: str) -> List[Dict[str, Any]]:
    """
    åˆ›å»ºç¬¦åˆOpenAI Visionæ ¼å¼çš„æ¶ˆæ¯
    
    Args:
        pil_images: PILå›¾åƒåˆ—è¡¨
        text_prompt: æ–‡æœ¬æç¤ºè¯
    
    Returns:
        List[Dict]: OpenAIæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
    """
    content = []
    
    # æ·»åŠ å›¾ç‰‡å†…å®¹
    for pil_img in pil_images:
        base64_image = pil_to_base64(pil_img, "PNG")
        content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/png;base64,{base64_image}"
            }
        })
    
    # æ·»åŠ æ–‡æœ¬å†…å®¹
    content.append({
        "type": "text",
        "text": text_prompt
    })
    
    return [{"role": "user", "content": content}]


# ============================================
# èŠ‚ç‚¹A: é€šç”¨LLMé…ç½®èŠ‚ç‚¹
# ============================================
class Universal_LLM_Config:
    """
    é€šç”¨LLMé…ç½®èŠ‚ç‚¹
    
    åŠŸèƒ½: ç”Ÿæˆé€šç”¨çš„LLMå®¢æˆ·ç«¯é…ç½®ï¼Œä¸ç»‘å®šç‰¹å®šå‚å•†
    æ”¯æŒ: è±†åŒ…ã€GPT-4oã€DeepSeekã€OpenAIç­‰å…¼å®¹OpenAI SDKçš„æœåŠ¡
    """
    
    # ========================================
    # èŠ‚ç‚¹å…ƒæ•°æ®
    # ========================================
    CATEGORY = "Ecommerce_LLM_Agent"
    FUNCTION = "create_config"
    RETURN_TYPES = ("LLM_CONFIG",)  # è‡ªå®šä¹‰è¾“å‡ºç±»å‹
    RETURN_NAMES = ("llm_config",)
    OUTPUT_NODE = False
    
    # ========================================
    # è¾“å…¥å®šä¹‰
    # ========================================
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                # APIåŸºç¡€URL
                "base_url": ("STRING", {
                    "default": DEFAULT_BASE_URL,
                    "placeholder": "https://api.openai.com/v1 æˆ–è±†åŒ…åœ°å€",
                    "tooltip": "LLM APIçš„åŸºç¡€URLï¼Œæ”¯æŒè±†åŒ…ã€OpenAIã€DeepSeekç­‰"
                }),
                # APIå¯†é’¥ (éšè—æ˜¾ç¤º)
                "api_key": ("STRING", {
                    "default": "",
                    "password": True,  # ComfyUIä¸­maskæ˜¾ç¤º
                    "tooltip": "æ‚¨çš„APIå¯†é’¥ï¼Œå°†è¢«å®‰å…¨å¤„ç†"
                }),
                # æ¨¡å‹åç§°
                "model_name": ("STRING", {
                    "default": DEFAULT_MODEL,
                    "tooltip": "æ¨¡å‹IDï¼Œå¦‚gpt-4oã€ep-xxxç­‰"
                }),
                # ç³»ç»Ÿæç¤ºè¯
                "system_prompt": ("STRING", {
                    "default": DEFAULT_SYSTEM_PROMPT,
                    "multiline": True,
                    "lines": 4,
                    "tooltip": "ç³»ç»Ÿçº§æç¤ºè¯ï¼Œå®šä¹‰AIåŠ©æ‰‹çš„è§’è‰²å’Œè¡Œä¸º"
                }),
            }
        }
    
    # ========================================
    # æ ¸å¿ƒå¤„ç†å‡½æ•°
    # ========================================
    def create_config(self, base_url: str, api_key: str, 
                      model_name: str, system_prompt: str) -> Tuple[Dict[str, Any]]:
        """
        åˆ›å»ºLLMé…ç½®å¯¹è±¡
        
        Args:
            base_url: APIåŸºç¡€URL
            api_key: APIå¯†é’¥
            model_name: æ¨¡å‹åç§°
            system_prompt: ç³»ç»Ÿæç¤ºè¯
        
        Returns:
            Tuple[Dict]: åŒ…å«é…ç½®å­—å…¸çš„å…ƒç»„
        """
        config = {
            "base_url": base_url,
            "api_key": api_key,
            "model_name": model_name,
            "system_prompt": system_prompt,
        }
        
        print(f"[Universal_LLM_Config] é…ç½®å·²åˆ›å»º: {model_name} @ {base_url}")
        return (config,)


# ============================================
# èŠ‚ç‚¹B: ç”µå•†æŠ€èƒ½è·¯ç”±èŠ‚ç‚¹ (å·²ä¼˜åŒ–æ‰¹é‡è¾“å‡ºé€»è¾‘)
# ============================================
class Ecommerce_Skill_Router:
    CATEGORY = "Ecommerce_LLM_Agent"
    FUNCTION = "process"
    
    # ä¿®æ”¹1ï¼šå®šä¹‰è¿”å›ç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶åŒ¹é…ä½ æˆªå›¾ä¸­çš„åç§°
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("batch_prompts", "formatted_summary")
    
    # ä¿®æ”¹2ï¼šå…³é”®ï¼å‘ŠçŸ¥ ComfyUI ç¬¬ä¸€ä¸ªè¾“å‡ºæ˜¯åˆ—è¡¨(List)ï¼Œç”¨äºè§¦å‘ä¸‹æ¸¸æ‰¹é‡ä»»åŠ¡
    OUTPUT_IS_LIST = (True, False) 
    
    OUTPUT_NODE = False

    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        skill_options = scan_skills_directory()
        return {
            "required": {
                "ä½¿ç”¨æŠ€èƒ½": ("BOOLEAN", {"default": True, "tooltip": "å¼€å¯åä½¿ç”¨æŠ€èƒ½æ¨¡æ¿ï¼Œå…³é—­åä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿"}),
                "æŠ€èƒ½é€‰æ‹©": (skill_options, {"tooltip": "é€‰æ‹©é¢„è®¾çš„ç”µå•†æŠ€èƒ½æ¨¡æ¿"}),
                "LLMé…ç½®": ("LLM_CONFIG", {"tooltip": "è¿æ¥Universal_LLM_ConfigèŠ‚ç‚¹çš„è¾“å‡º"}),
                "è¾“å‡ºæ¨¡å¼": (["åˆ†æ‰¹è¾“å‡º", "åˆå¹¶è¾“å‡º"], {"default": "åˆ†æ‰¹è¾“å‡º"}),
                "ç”Ÿå›¾æ•°é‡": ("INT", {"default": 4, "min": 1, "max": 20, "tooltip": "éœ€è¦ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡"}),
            },
            "optional": {
                "è‡ªå®šä¹‰æŠ€èƒ½ç›®å½•": ("STRING", {"default": "", "placeholder": "ç•™ç©ºä½¿ç”¨é»˜è®¤ç›®å½•"}),
                "å…³é”®è¯æœç´¢": ("STRING", {"default": "", "placeholder": "è¾“å…¥å…³é”®è¯è‡ªåŠ¨åŒ¹é…æŠ€èƒ½"}),
                "åˆ·æ–°æŠ€èƒ½åˆ—è¡¨": ("BOOLEAN", {"default": False, "tooltip": "å‹¾é€‰åé‡æ–°æ‰«æskillsç›®å½•"}),
                "å›¾ç‰‡1": ("IMAGE", {}),
                "å›¾ç‰‡2": ("IMAGE", {}),
                "å›¾ç‰‡3": ("IMAGE", {}),
                "å›¾ç‰‡4": ("IMAGE", {}),
                "äº§å“åç§°": ("STRING", {"default": "", "placeholder": "äº§å“åç§°ï¼ˆå¯é€‰ï¼‰"}),
                "ç›®æ ‡äººç¾¤": ("STRING", {"default": "", "placeholder": "ç›®æ ‡äººç¾¤ï¼ˆå¯é€‰ï¼‰"}),
                "äº§å“å‚æ•°": ("STRING", {"default": "", "multiline": True, "placeholder": "äº§å“å‚æ•°ï¼ˆå¯é€‰ï¼‰"}),
                "å–ç‚¹": ("STRING", {"default": "", "multiline": True, "placeholder": "å–ç‚¹ï¼ˆå¯é€‰ï¼‰"}),
                "å¹³å°": ("STRING", {"default": "", "placeholder": "å¹³å°ï¼ˆå¯é€‰ï¼‰"}),
                "è¯­è¨€": ("STRING", {"default": "", "placeholder": "è¯­è¨€ï¼ˆå¯é€‰ï¼Œå¦‚ï¼šä¸­æ–‡/Englishï¼‰"}),
                "è‡ªå®šä¹‰æ¨¡æ¿": ("STRING", {"default": "", "multiline": True, "placeholder": "è‡ªå®šä¹‰æ¨¡æ¿ï¼ˆå¯é€‰ï¼‰"}),
            }
        }

    def process(self, ä½¿ç”¨æŠ€èƒ½: bool, æŠ€èƒ½é€‰æ‹©: str, LLMé…ç½®: Dict[str, Any],
                è¾“å‡ºæ¨¡å¼: str, ç”Ÿå›¾æ•°é‡: int,
                è‡ªå®šä¹‰æŠ€èƒ½ç›®å½•: str = "",
                å…³é”®è¯æœç´¢: str = "",
                åˆ·æ–°æŠ€èƒ½åˆ—è¡¨: bool = False,
                å›¾ç‰‡1: Optional[torch.Tensor] = None,
                å›¾ç‰‡2: Optional[torch.Tensor] = None,
                å›¾ç‰‡3: Optional[torch.Tensor] = None,
                å›¾ç‰‡4: Optional[torch.Tensor] = None,
                äº§å“åç§°: str = "", ç›®æ ‡äººç¾¤: str = "",
                äº§å“å‚æ•°: str = "", å–ç‚¹: str = "",
                å¹³å°: str = "", è¯­è¨€: str = "",
                è‡ªå®šä¹‰æ¨¡æ¿: str = "") -> Tuple[List[str], str]:
        
        if not DEPS_OK:
            return (["ä¾èµ–ç¼ºå¤±"], "è¯·å®‰è£…å¿…è¦çš„Pythonåº“")

        try:
            # å¤„ç†åˆ·æ–°è¯·æ±‚
            if åˆ·æ–°æŠ€èƒ½åˆ—è¡¨:
                scan_skills_directory(force_refresh=True, custom_path=è‡ªå®šä¹‰æŠ€èƒ½ç›®å½•)
                print("[Ecommerce_Skill_Router] æŠ€èƒ½åˆ—è¡¨å·²åˆ·æ–°")
            
            # å¤„ç†å…³é”®è¯æœç´¢
            final_skill = æŠ€èƒ½é€‰æ‹©
            if å…³é”®è¯æœç´¢ and å…³é”®è¯æœç´¢.strip():
                matched = search_skill_by_keyword(å…³é”®è¯æœç´¢)
                if matched:
                    final_skill = matched
                    print(f"[Ecommerce_Skill_Router] ä½¿ç”¨å…³é”®è¯åŒ¹é…çš„æŠ€èƒ½: {final_skill}")
                else:
                    print(f"[Ecommerce_Skill_Router] æœªæ‰¾åˆ°åŒ¹é…'{å…³é”®è¯æœç´¢}'çš„æŠ€èƒ½ï¼Œä½¿ç”¨é»˜è®¤é€‰æ‹©")
            
            # 1. æ„å»ºäº§å“ä¿¡æ¯ä¸Šä¸‹æ–‡
            context_parts = []
            if äº§å“åç§°:
                context_parts.append(f"äº§å“åç§°: {äº§å“åç§°}")
            if ç›®æ ‡äººç¾¤:
                context_parts.append(f"ç›®æ ‡äººç¾¤: {ç›®æ ‡äººç¾¤}")
            if äº§å“å‚æ•°:
                context_parts.append(f"äº§å“å‚æ•°: {äº§å“å‚æ•°}")
            if å–ç‚¹:
                context_parts.append(f"å–ç‚¹: {å–ç‚¹}")
            if å¹³å°:
                context_parts.append(f"å¹³å°: {å¹³å°}")
            if è¯­è¨€:
                context_parts.append(f"è¯­è¨€: {è¯­è¨€}")
            
            product_context = "\n".join(context_parts) if context_parts else "è¯·æ ¹æ®å›¾ç‰‡å†…å®¹è¿›è¡Œåˆ†æ"
            
            # 2. åŠ è½½æ¨¡æ¿é€»è¾‘ï¼šæ ¹æ®"ä½¿ç”¨æŠ€èƒ½"å¼€å…³å†³å®š
            if ä½¿ç”¨æŠ€èƒ½:
                template = load_skill_template(final_skill, è‡ªå®šä¹‰æŠ€èƒ½ç›®å½•)
                if not template:
                    return (["æŠ€èƒ½æ¨¡æ¿åŠ è½½å¤±è´¥"], "è¯·æ£€æŸ¥æŠ€èƒ½é€‰æ‹©æˆ–ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿")
            else:
                if not è‡ªå®šä¹‰æ¨¡æ¿ or not è‡ªå®šä¹‰æ¨¡æ¿.strip():
                    return (["è¯·æä¾›è‡ªå®šä¹‰æ¨¡æ¿å†…å®¹"], "å…³é—­æŠ€èƒ½åå¿…é¡»å¡«å†™è‡ªå®šä¹‰æ¨¡æ¿")
                template = è‡ªå®šä¹‰æ¨¡æ¿.strip()
            
            # 3. æ„å»ºæœ€ç»ˆæç¤ºè¯ï¼Œæ˜ç¡®å‘ŠçŸ¥LLMç”ŸæˆæŒ‡å®šæ•°é‡çš„æç¤ºè¯
            final_prompt = template.format(
                platform=å¹³å° or "ç”µå•†å¹³å°",
                selling_points=product_context,
                batch_count=ç”Ÿå›¾æ•°é‡
            )
            final_prompt += f"\n\nè¯·ä¸¥æ ¼ç”Ÿæˆ{ç”Ÿå›¾æ•°é‡}è¡Œç‹¬ç«‹çš„æç¤ºè¯ï¼Œæ¯è¡Œä¸€ä¸ªå®Œæ•´çš„promptã€‚"

            # 2. å¤„ç†å›¾ç‰‡é€»è¾‘ (æ”¯æŒ4ä¸ªç‹¬ç«‹è¾“å…¥)
            pil_images = []
            for img_tensor in [å›¾ç‰‡1, å›¾ç‰‡2, å›¾ç‰‡3, å›¾ç‰‡4]:
                if img_tensor is not None:
                    pil_images.append(tensor_to_pil(img_tensor))

            # 3. è°ƒç”¨ LLM
            response_text = self._call_llm(LLMé…ç½®, final_prompt, pil_images)
            
            if response_text is None:
                return (["APIè°ƒç”¨å¤±è´¥"], "è¯·æ£€æŸ¥ç½‘ç»œæˆ–API Key")

            # 4. ä¿®æ”¹è¾“å‡ºé€»è¾‘ï¼šå°†æ–‡æœ¬æŒ‰è¡Œåˆ‡åˆ†ä¸ºåˆ—è¡¨
            # è¿‡æ»¤æ‰ç©ºè¡Œï¼Œç¡®ä¿æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ Prompt
            lines = [line.strip() for line in response_text.split('\n') if line.strip()]
            
            # å®Œæ•´çš„åŸå§‹æ–‡æœ¬ä½œä¸ºæ€»ç»“è¾“å‡º
            formatted_summary = response_text.strip()

            print(f"[Ecommerce_Skill_Router] æˆåŠŸç”Ÿæˆ {len(lines)} æ¡ç‹¬ç«‹æç¤ºè¯")
            
            # ä¿®æ”¹3ï¼šè¿”å› (åˆ—è¡¨, å­—ç¬¦ä¸²)
            return (lines, formatted_summary)

        except Exception as e:
            traceback.print_exc()
            return ([f"é”™è¯¯: {str(e)}"], str(e))

    # _call_llm å‡½æ•°ä¿æŒä¸å˜...
    # ========================================
    # LLM APIè°ƒç”¨å‡½æ•°
    # ========================================
    def _call_llm(self, llm_config: Dict[str, Any], 
                  prompt: str, 
                  images: List[PILImage.Image]) -> Optional[str]:
        """
        è°ƒç”¨LLM APIè·å–å“åº”
        
        Args:
            llm_config: LLMé…ç½®
            prompt: æ–‡æœ¬æç¤ºè¯
            images: PILå›¾åƒåˆ—è¡¨
        
        Returns:
            Optional[str]: LLMå“åº”æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
            client = OpenAI(
                base_url=llm_config["base_url"],
                api_key=llm_config["api_key"],
            )
            
            # æ„å»ºæ¶ˆæ¯
            messages = []
            
            # æ·»åŠ ç³»ç»Ÿæç¤ºè¯
            if llm_config.get("system_prompt"):
                messages.append({
                    "role": "system",
                    "content": llm_config["system_prompt"]
                })
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ (æ–‡æœ¬+å›¾ç‰‡)
            if images:
                # å¤šæ¨¡æ€æ¶ˆæ¯
                content = []
                
                # æ·»åŠ å›¾ç‰‡
                for pil_img in images:
                    base64_img = pil_to_base64(pil_img, "PNG")
                    content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_img}",
                            "detail": "high"
                        }
                    })
                
                # æ·»åŠ æ–‡æœ¬
                content.append({
                    "type": "text",
                    "text": prompt
                })
                
                messages.append({
                    "role": "user",
                    "content": content
                })
            else:
                # çº¯æ–‡æœ¬æ¶ˆæ¯
                messages.append({
                    "role": "user",
                    "content": prompt
                })
            
            print(f"[Ecommerce_Skill_Router] è°ƒç”¨æ¨¡å‹: {llm_config['model_name']}")
            
            # å‘é€è¯·æ±‚
            response = client.chat.completions.create(
                model=llm_config["model_name"],
                messages=messages,
                temperature=0.7,
                max_tokens=2048,
            )
            
            # æå–å“åº”æ–‡æœ¬
            result = response.choices[0].message.content
            
            print(f"[Ecommerce_Skill_Router] APIè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(result)} å­—ç¬¦")
            return result
            
        except Exception as e:
            print("=" * 60)
            print("[Ecommerce_Skill_Router] LLM APIè°ƒç”¨å¤±è´¥:")
            traceback.print_exc()
            print("=" * 60)
            return None


# ============================================
# èŠ‚ç‚¹æ˜ å°„ (ä¾›ComfyUIåŠ è½½ä½¿ç”¨)
# ============================================
NODE_CLASS_MAPPINGS = {
    "Universal_LLM_Config": Universal_LLM_Config,
    "Ecommerce_Skill_Router": Ecommerce_Skill_Router,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "Universal_LLM_Config": "ğŸ¤– é€šç”¨LLMé…ç½®",
    "Ecommerce_Skill_Router": "ğŸ›’ ç”µå•†æŠ€èƒ½è·¯ç”±",
}
